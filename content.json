{"pages":[{"title":"about","text":"Try to be a good 炼丹师.","link":"/about/index.html"},{"title":"Test","text":"","link":"/Test/index.html"}],"posts":[{"title":"记录一下维护hexo常用的几个命令","text":"整理一部分最常用的hexo命令 维护hexo常用的几个命令生成，参数-d可以生成后部署，等效hexo d -g 12345hexo ghexo generatehexo g -dhexo d -g 启动服务 12hexo shexo server 部署，部署前需要正确配置_config.yml 12hexo dhexo deploy 新建文章 12hexo n &quot;article&quot;hexo new &quot;article&quot; 清除缓存 1hexo clean","link":"/Common-commands-of-using-hexo/"},{"title":"CSGO中常用命令整理 CSGO common commands","text":"网上有很多整理的，但是很多很实用的命令简中社区查不到，因此整理一份我个人觉得更实用的，长期更新。 最最最基本的指令connect [ip]:[port] password [pwd] 连接某服务器 disconnect retry 断开连接/重连 quit 退出游戏 net_graph 0/1 关闭/显示网络状况，如fps、ping、loss、choke、var、tick等 fps_max 400 最高fps 服务器内的指令基本的mp_restartgame 1 1秒后重开游戏 mp_autoteambalance 0/1 自动平衡关闭/开启 mp_maxmoney 16000 最高金钱 mp_startmoney 16000 出生金钱 mp_buy_anywhere 1 任意地点购买 mp_buytime 15 开局购买时间限制 mp_roundtime 60 回合时间，单位分钟 mp_maxrounds 30 最高回合数 mp_freezetime 0 每局出生原地冻结时间0秒 mp_warmup_end 立即结束热身时间 mp_friendlyfire 0/1 关闭/开启友伤 mp_limitteams 2 阵营差异 maxplayers 16 最多玩家数 map de_inferno 切换地图(如de_mirage、de_inferno) maps 列出该服务器所有地图 mp_overtime_enable 0/1 关闭/开启加时赛 mp_randomspawn 0/1 关闭/开启随机出生点 mp_teammates_are_enemies 1 无阵营区分，适合死斗 exec gamemode_[gamemode name] 更改游戏模式 sv_cheats 0/1 关闭/开启作弊功能，部分功能需要此选项开启 sv_gravity 800 重力，默认800 give weapon_[weapon name] 获得武器 god gods 自己/所有人godmode r_drawothermodels 2 透视绘制 noclip 无视墙 sv_infinite_ammo 0/1/2 无限弹药 host_timescale 1.0 时间倍率，用来调速 Bot相关bot_add 随机增加一个bot bot_add_ct 增加一名CT bot bot_add_t 增加一名T bot bot_kick 踢出所有bot bot_kill 杀死所有bot bot_stop 1 bot原地不动 bot_freeze 1 冻结所有bot bot_difficulty 0/1/2/3 设置bot难度 语音频道sv_alltalk 0/1 关闭/开启敌方语音频道 有时需要配合sv_talk_enemy_dead 0/1 sv_talk_enemy_living 0/1 sv_full_alltalk 0/1 关闭/开启所有人互通的语音频道，包括观众 sv_deadtalk 0/1 关闭/开启天堂语音频道（死人说话） 服务器内的进阶指令跑图相关sv_showimpacts 1 显示子弹落点 sv_showimpacts_time 15 子弹落点停留时间 sv_grenade_trajectory 1 显示投掷物轨迹 sv_grenade_trajectory_time 15 投掷物轨迹停留时间 连跳相关sv_enablebunnyhopping 1 允许连跳 sv_autobunnyhopping 1; 自动连跳 弹道扩散相关weapon_accuracy_nospread 0/1 枪口不扩散，类似跳狙飞人 其它mp_damage_headshot_only 1 仅限爆头击杀 本篇将会长期更新。 针对更多需要，可以查看这个Link CS:GO Commands List.","link":"/CSGO-common-commands/"},{"title":"LaTeX插入图片及多行多列图片排版","text":"LaTeX插入一张图片首先导入宏包 1\\usepackage{graphicx} 插入图片 12345\\begin{figure}[htbp] \\centering \\includegraphics[width=0.6\\textwidth]{figures/image.png} \\caption{题注}\\end{figure} 其中，[htbp]是控制图片位置的参数 param position h 当前位置 t 页面顶部 b 页面底部 p 浮动 插入并列的两张独立图片使用minipage分栏实现并列图片插入 123456789101112\\begin{figure}[htbp] \\begin{minipage}[t]{0.5\\linewidth} \\centering \\includegraphics[width=0.8\\textwidth]{figures/image1.png} \\caption{题注1} \\end{minipage}% \\begin{minipage}[t]{0.5\\linewidth} \\centering \\includegraphics[width=0.8\\textwidth]{figures/image2.png} \\caption{题注2} \\end{minipage}\\end{figure} 效果如下 插入并列的两张不独立的图片直接连续使用两次\\includegraphics[]{}即可，\\hspace{}表示间距。 1234567\\begin{figure}[htbp] \\centering \\includegraphics[width=0.4\\textwidth]{figures/image1.png} \\hspace{0.1in} \\includegraphics[width=0.4\\textwidth]{figures/image2.png} \\caption{Result}\\end{figure} 效果如下 插入多行多列，其中每列算一个独立图片写Report的时候突然有这样一个需求，就是实现下图这种每列算一个独立图片的多行多列图片。每个独立图片里面其实有两张图片。 使用minipage分栏，然后使用\\\\实现图片换行竖排显示。具体实现办法如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243\\begin{figure}[htbp] \\centering \\begin{minipage}[t]{0.3\\linewidth} \\centering \\includegraphics[width=4cm]{figures/image11.png} \\\\ \\includegraphics[width=4cm]{figures/image12.png} \\caption{\\\\1} \\end{minipage} \\begin{minipage}[t]{0.3\\linewidth} \\centering \\includegraphics[width=4cm]{figures/21.png} \\\\ \\includegraphics[width=4cm]{figures/22.png} \\caption{\\\\2} \\end{minipage} \\begin{minipage}[t]{0.3\\linewidth} \\centering \\includegraphics[width=4cm]{figures/31.png} \\\\ \\includegraphics[width=4cm]{figures/32.png} \\caption{\\\\3} \\end{minipage}\\end{figure}\\begin{figure}[htbp] \\centering \\begin{minipage}[t]{0.3\\linewidth} \\centering \\includegraphics[width=4cm]{figures/41.png} \\\\ \\includegraphics[width=4cm]{figures/42.png} \\caption{\\\\4} \\end{minipage} \\begin{minipage}[t]{0.3\\linewidth} \\centering \\includegraphics[width=4cm]{figures/51.png} \\\\ \\includegraphics[width=4cm]{figures/52.png} \\caption{\\\\5} \\end{minipage} \\begin{minipage}[t]{0.3\\linewidth} \\centering \\includegraphics[width=4cm]{figures/61.png} \\\\ \\includegraphics[width=4cm]{figures/62.png} \\caption{\\\\6} \\end{minipage}\\end{figure} 多行多列子图使用/subfigure可以划分子图，具体做法先不写了，可以先参考一下这篇latex 排列多个子图，以后可能填坑。","link":"/LaTeX-insert-images/"},{"title":"之前的几篇水博 Previous blogs","text":"鄙人不才，一共也没写过几篇博客也没啥质量，哈哈哈哈哈哈🤣🤣🤣。但是还是想把东西都放一起，所以放在这儿了。以前还学习过Android开发，现在退坑了。 I haven’t written a few blogs in total (xDDDDD🤣🤣🤣), but I still wanted to collect them together here. No longer messing with Android now👋👋👋. Links:Android开发-向ViewPager动态添加时报错java.lang.IllegalStateException Android开发-Gson解析数据 Android开发-RecyclerView简单实现对Item的事件响应以及交互效果 Raspberry Pi 3B音频口底噪太大的解决办法 Realtek 8822be无线网卡在Ubuntu16/17上驱动问题的完美解决方案","link":"/Previous-articles/"},{"title":"解决Powershell阻止脚本运行遇到的问题 Solution to powershell disable runing scripts","text":"当使用命令 set-executionpolicy remotesigned 解除Powershell对脚本运行的限制时，目前的用户可能没有被应用新的策略。 When using the command set-executionpolicy remotesigned to allow scripts running on powershell, current user may not be appled the change. 123456set-executionpolicy : Windows PowerShell 已成功更新你的执行策略，但在更具体的作业域中定义的策略覆盖了该设置。由于发生覆盖，你的外壳程序将保留其当前的有效执行策略 Restricted。请键入“Get-ExecutionPolicy -List”以查看你的执行策略设置。有关详细信息，请参阅“Get-Help Set-ExecutionPolicy”。所在位置 行:1 字符: 1+ set-executionpolicy remotesigned+ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~+ CategoryInfo : PermissionDenied: (:) [Set-ExecutionPolicy], SecurityException+ FullyQualifiedErrorId : ExecutionPolicyOverride,Microsoft.PowerShell.Commands.SetExecutionPolicyCommand 这时可以使用命令Set-ExecutionPolicy RemoteSigned -Scope CurrentUser来更新当前用户的策略，然后就可以轻松地在powershell运行脚本啦~ In this case, we can use command Set-ExecutionPolicy RemoteSigned -Scope CurrentUser to update the policy on current user. It will work now.","link":"/Powershell-disable-runing-scripts/"},{"title":"安装hexo-asset-image导致Hexo插入图片无法显示的解决办法 Solution to insert pics in Hexo when hexo-asset-image is installed","text":"请根据本文使用的Hexo版本自测本文时效性。Please check the version of Hexo before reading. 1234$ hexo -vINFO Validating confighexo: 6.1.0hexo-cli: 4.3.0 NO!$ npm install hexo-asset-image –save 正确的做法Hexo已经支持Markdown语法插入图片了！！Hexo已经支持Markdown语法插入图片了！！Hexo已经支持Markdown语法插入图片了！！网上说hexo不能用Markdown相对引用图片的资料已经过时了！！*IMPORTANT: Unlike the past, Hexo already supports Markdown syntax for inserting images! 以下摘自官方：The following is the part of official document: Embedding an image using markdown hexo-renderer-marked 3.1.0 introduced a new option that allows you to embed an image in markdown without using asset_img tag plugin. To enable: _config.ymlpost_asset_folder: truemarked:prependRoot: truepostAsset: true Once enabled, an asset image will be automatically resolved to its corresponding post’s path. For example, “image.jpg” is located at “/2020/01/02/foo/image.jpg”, meaning it is an asset image of “/2020/01/02/foo/“ post, ![](image.jpg) will be rendered as &lt;img src=&quot;/2020/01/02/foo/image.jpg&quot;&gt;. 所以其实Hexo已经可以不使用繁杂的标签{% asset_img example.jpg This is an example image %}去插入图片了,可以直接使用Markdown语法并进行相对路径引用了，如![](image.jpg)。So actually we don’t need to use the nasty form {% asset_img example.jpg This is an example image %} to insert images. Feel free to use the Markdown way![](image.jpg). 错误的做法一些网上的资料因为年代久远且被不断翻新会建议使用npm install hexo-asset-image –save命令安装hexo-asset-image进行图片插入。在新版本Hexo不要这样做，否则会导致最终的绝对路径出现bug导致图片无法引用。如果已经执行了，请回退node_modules目录、package.json等文件到之前的版本，并使用hexo clean清除db.json和public目录然后重新生成。 Some outdated tutorials may tell you that you have to use npm install hexo-asset-image –save to install hexo-asset-image for inserting images. DO NOT DO THAT NOW, cause it will make a bug in generated absolute paths. And the images will be not available in your blogs.If you have already installed it, Please roll back the node_modules directory, package.json and other files to the previous version and use hexo clean to clear the db.json and public directory and then regenerate them.","link":"/Solution-to-insert-pics-in-Hexo/"},{"title":"PyCharm下的Jupyter Notebook输出图片颜色反转的原因","text":"今天debug两小时不知道为什么输入的图片画出来颜色怪怪的，以为是通道不对，调了半天发现RGB通道根本没问题，最后发现是pycharm会在深色皮肤下默认反转jupyter notebook输出图片的颜色，吐了。 修改如下设置回归正常颜色。","link":"/pycharm-jupyter-inverse-color/"},{"title":"Windows11&#x2F;10快捷键启动缓慢的解决方案 Solution to slow start with hot key on Windows11&#x2F;10","text":"Windows上的快捷启动会变得缓慢。 Starting with hotkey always run slow on Windows. 快捷键启动指的是诸如win+shift+数字键和Ctrl+Alt+自定义键的快捷键启动方式，比如自定义Ctrl+Alt+T为Windows Terminal的快捷键。 Starting with hotkey means hotkeys like win+shift+num and Ctrl+Alt+custom keyon Windows. For example, people often set Ctrl+Alt+T to be the hotkey of starting Windows Terminal. 但是Windows有个bug会使得快捷键启动反应很慢。 But there is a bug on Windows making it slow when starting something. Windows10在Windows10上，进入设置，隐私，后台应用，关闭“设置”的后台权限即可解决。 On Windows10, you can solve that by going to Settings, Privacy, Background Apps and turning off the permission of “Setting”. Windows11Windows11中，微软移除了Windows10里的后台应用菜单，但是可以进入应用设置菜单关闭这个选项。在Windows11上，在开始菜单右键设置，进入应用设置，将后台应用权限修改为“从不”。 In Windows 11, Microsoft removed the background application menu from Windows 10. On Windows 11, now you need to right-click on Settings in the Start menu, go to Application Settings and change the background application permission to “Never”.","link":"/Solution-to-slow-start-with-hot-key-on-Windows11-10/"},{"title":"ModuleNotFoundError: No module named &#39;flaxformer&#39;","text":"✨Check the date of this article before reading!✨ No module named ‘flaxformer’Recently, Google used more and more models built on JAX and Flax. When I try to run Vision Transformer pretrained models created by Google, I got the following error. 1ModuleNotFoundError: No module named 'flaxformer' But I already installed the requirements.txt, I was confused about the error. And the flaxformer can not be installed by using pip install [package name] since it did not release on PyPI. Then I checked the repositories of flax and flaxformer:https://github.com/google/flaxhttps://github.com/google/flaxformer FixThe module flaxformer was not released, so it can be installed by: 1pip install git+https://github.com/google/flaxformer Solved.🎉","link":"/No-module-named-flaxformer/"},{"title":"在Linux上训练深度学习模型常用的一些命令整理","text":"最近在用学校的服务器训练一些模型，所以整理几个很常用的命令……带有端口转发的ssh，可以方便在Linux服务器上开个Jupyter Notebook在本机连入 1ssh -L localhost:[local port]:localhost:[remote port] [username]@[remote address] 查看训练卡详情，包括卡的温度、实时功率和显存占用等其中watch可以常驻终端动态查看，参数-n可以控制更新频率 1nvidia-smi 1watch nvidia-smi 1watch -n 0.1 nvidia-smi 查看系统的整体运行情况进入后按e可以调整下半部分单位，E调整上半部分单位，如k、m、g、t、p 1top 列出conda包含的环境 1conda env list","link":"/Common-commands-when-training-deep-learning-models-on-Linux/"},{"title":"Vision Transformer论文解读","text":"发表于ICLR2021的Vision Transformer已经成为后续Transformer模型在CV领域进一步发展的基石，本文为初代Vision Transformer论文An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale的解读。 Vision Transformer的pytorch实现可以看我放在Github里的实现：Vision Transformer pytorch - Github，欢迎前来star&amp;fork✨✨✨ Why首先就是为什么要设计Vision Transformer？过往CV领域基本上主要就是CNN的各种变体的天下，可以说对CNN的依赖非常之深。而由于Transformer在NLP领域的大放异彩，大家都在研究如何使用新的模型代替CNN之前的工作。 将Transformer移植到CV领域的一个问题是，NLP领域里，一个句子的长度不会长到无法处理，但是CV领域的一张224*224的图片展开就长达50,176，将这样长的序列输入到Transformer里是无法完成的任务😥！将图像展开成一维数组会导致输入长度平方增长，这是将图像输入到Transformer要解决的首要问题。 所以正如论文里所说，研究者们尝试了许多种不同的方法来解决这个问题，比如仅仅在局部邻域应用注意力机制，亦或是轴注意力等方式减少计算量，除此之外还有将图像拆分成2*2patch的方法（其实这个思路已经近乎等同于Vision Transformer了）等等。 Structure of Vision Transformer下图就是论文中Vision Transformer的结构： 结构解读： ①Patching：首先Vision Transformer将图片分割成n*n个patch，这样每个patch展开的长度就很大程度地缩小了。e.g.假设图像是224*224大小，设定每个patch的大小为16*16，那么图像就分割成了14*14个patch，并且每个大小为16*16的patch展开之后为256，这个大小就是模型可以处理的了！ ②Position Embedding：如图，patch之后使用一个Linear Projection层将所有patch映射，其实这里就是所有patch过了一个线性层。然后将过了线性层的所有patch进行位置编码，这里一开始我也不知道是怎样生成的位置编码，但其实就是每个位置随机生成的位置编码，并且这个编码是可训练的，后面会进一步说一下位置编码的问题。（另外，在实现中，patching + linear projection的操作可以等价于一个kernel size和stride都等于patch size的Conv2D。这个也很好理解，就是每次卷积核裁出一个patch size的patch，然后再走这么多的步长，就相当于分割了patch，最后卷积层的运算就相当于线性层。所以基本上这步用一个kernel size和stride都等于patch size的Conv2D卷积层就可以做到！） ③Class Token：这里还有一个cls token，这个方法其实源自Bert模型。根据原文，最后MLP Head分类的时候也只使用cls token中的信息。但是其实使用cls token或者不使用cls token转而对所有Encoder的输出进行全局平均池化，个人认为没有什么太大的区别，因为其实cls token本质就是“窥探”地综合了所有patch的信息。 ④Transformer Encoder：Vision Transformer中其实没有Decoder结构，只使用Encoder。这里我们可以将其与Transformer的结构进行对比来发现Vision Transformer的改进。其实整体和NLP的原Transformer Encoder的结构非常相似，作者也是尽可能在最小程度修改原模型的程度上将Transformer应用到CV领域来。一个小的区别是两个Layer Norm在Encoder中的位置提前了。输入进入Layer Norm层，后接一个多头自注意力机制，一个残差结构，后面又是一个Layer Norm层，接一个MLP，一个残差结构。这就构成了一个ViT的Encoder Block，然后可以按所需要的网络深度堆叠多个。 ⑤MLP Head：正如前面所说，原文只使用cls token的输出作为MLP Head的输入进行分类。但是使用池化我认为也是可以的，因为无论如何只要MLP Head可以获得到整体的特征信息即可。 SOTA, inductive bias and training from scartch论文是Google Brain和Google Research的团队做的，计算资源那是相当滴丰富（羡慕羡慕羡慕羡慕好羡慕🤤🤤🤤）。 可以看出，在大型数据集上预训练的ViT模型可以完爆之前的巨型CNN——ResNet152x4了，效果确实有非常明显地提升，是当时的state of the art了。 但是代价是什么呢？不同于CNN中的卷积结构，Transformer完全没有inductive bias（归纳偏置）。卷积层本身就具有的translation equivariance（平移等价性）和locality（局部性），Transformer是完全没有的。所以相当于这部分东西就得模型自己去学习😥，这一定程度就是位置编码的工作了。 论文做了非常多的实验，其中就包括位置编码，比如1D位置编码（也就是上面所说的）、2D位置编码、Rel.位置编码、没有位置编码的对比实验等。最后发现只要有位置编码，无所谓是哪种位置编码的，效果都差不多其实。因为位置编码最后无论如何都能学习出来2D的特征，这也涉及到另一个实验——位置编码的余弦相似度那个实验，见下图中间那个小图： （该实验就是计算在模型经过训练之后，不同位置的位置编码之间的余弦相似度。该实验的复现也可见我们的Github仓库：Position embedding similarity。另有RGB filter的实验复现（即上图中第一个小图）：RGB filter） 可以看到，其实最后通过位置编码的学习，可以获得到这部分inductive bias，但与此同时，这需要大量的且更general的图像数据集和大规模的训练支撑，在Google JFT300M这种超超超超大数据集上预训练的效果才是最好的，这意味着这会比CNN结构的网络消耗更多的资源和更多的时间。简而言之，Vision Transformer还是非常难以训练的，因为需要大量的成本去训练。 后续的另一篇论文Three things everyone should know about Vision Transformers也有更多的实验和研究。与其你在数据集上training from scartch（从0开始训练），不如拿预训练好的模型直接fine-tune（微调）。Training from scartch不仅消耗更多的资源，而且效果还不如在超大训练集上预训练后微调的模型。总的来说，迁移模型然后fine-tune才是你要做的。 尾巴总的来说，Vision Transformer打破了CNN在CV领域的垄断局面，但是也具有非常明显的问题，毕竟工业界不是为了刷点，工业界也需要轻量可部署的模型。但是Vision Transformer也算是一个重要的开端✨，后续产生了非常多的Vision Transformer变体，比如和CNN结合，比如在其他CV任务的应用，效果都非常非常好。 我写这篇解读距离我亲手搭建已经过去了一段时间，所以难免可能会有一些勘误或者表达不准确的地方，欢迎读者指出，我将感激不尽😊😊😊。 ReferencesVision Transformer: An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale Transformer: Attention Is All You Need Bert: BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding Three things of ViT: Three things everyone should know about Vision Transformers ResNet: Deep Residual Learning for Image Recognition BiT: Big Transfer (BiT): General Visual Representation Learning","link":"/Vision-Transformer/"},{"title":"PVOD Regression - Photovoltaic power output prediction based on weather data","text":"PVOD is a public dataset that contains real photovoltaic power output and weather condition data. The regression of this dataset can be used to forecast PV power. The code is available on my Github repo SmallSquare/PVOD_Regression. Feel free to correct me😊. IntroductionWhy do this? I planned to use this dataset for my research project, but then my supervisor provided me with a better private dataset for research. So some very simple work done before on this dataset can be shown here as a simple example of data processing and modelling. Why does the photovoltaic power output need to be predicted? Unlike conventional power generation, photovoltaic power is very unstable. But it is heavily influenced by day and night and the weather conditions. So, using weather data is a good idea to forecast the PV power. DatasetThis dataset includes data from ten power stations in relatively close geographical proximity. I will use station03 as an example. We can learn some basic information from the provided metadata. Here are columns of the metadata: Metadata: Station_ID Capacity PV_Technology Panel_size Module Inverters Layout Panel_Number Array_Tilt Pyranometer Longitude Latitude Then, we just delve directly into the specific data. station03 has 14688 entries. Here are categorized columns of the dataset of station03: Time: datetime Weather: nwp_globalirrad nwp_directirrad nwp_temperature nwp_humidity nwp_windspeed nwp_winddirection nwp_pressure lmd_totalirrad lmd_diffuseirrad lmd_temperature lmd_pressure lmd_winddirection lmd_windspeed Photovoltaics: power We now have a general view of what the data set looks like. Further, to set the stage for modelling, a correlation analysis is required. It can be found in the heat map that features of radiation take the highest correlation to the power output. But we will drop columns of radiation later because sometimes the radiation is not that easy to measure without a pyranometer and this is almost linearly related to the power output. This may not reflect value in the actual forecast. Also, we can observe the distribution of the power output. Feature engineering and feature selectionThe datetime is pretty important and we need to do some engineering on it. For a cyclic feature like date or time, to keep the distance among values in a cyclic feature reasonable, we should encode it. The exact method and rationale can be found in Pierre-Louis Bescond’s blog → Cyclical features encoding, it’s about time. His blog is easy to understand and has inspired me well. Then, we only select the following locally measured data:(As you can see, datetime now becomes time_sin, time_cos, date_sin and date_cos) 12345678[lmd_temperature','lmd_pressure','lmd_winddirection','lmd_windspeed','time_sin','time_cos','date_sin','date_cos'] We can do a new correlation analysis on processed features and target variable power. ModellingWell, now we are finally ready to model. Since this is just a simple try on PVOD, I will use models in scikit-learn package with their default hyperparameters.(lazy way to try😥, but don’t use default in your real research😉) Here is the performance comparison of models. The following performance is for reference only, as we have not looked carefully for hyperparameters. Model MAE MSE RMSE R-square RF 0.5170 1.1366 1.0661 0.9523 GBM 0.9619 2.5754 1.6048 0.8919 MLP 1.4072 4.2578 2.0634 0.8213 Although we didn’t work on hyperparameters, Random Forest still give us a good prediction. The blue line is the prediction, and the black line is the ground truth, we can see how close the prediction of RF made is to the ground truth. Feature importanceThe RF and GBM can tell the importance of features: 1234567891011121314151617- RF Feature Importance -lmd_temperature &gt; 9.6921 %lmd_pressure &gt; 3.6568 %lmd_winddirection &gt; 1.0712 %lmd_windspeed &gt; 1.1253 %time_sin &gt; 52.7894 %time_cos &gt; 24.5264 %date_sin &gt; 2.6910 %date_cos &gt; 4.4477 % 1234567891011121314151617- GBM Feature Importance -lmd_temperature &gt; 8.7980 %lmd_pressure &gt; 1.5802 %lmd_winddirection &gt; 0.1962 %lmd_windspeed &gt; 0.6686 %time_sin &gt; 59.7374 %time_cos &gt; 25.9409 %date_sin &gt; 1.5174 %date_cos &gt; 1.5614 % It can be noticed that features of time are the most important features, as irradiance varies at different times of the day. Apart from this, the temperature is the next most important feature. Pressure and date also have an impact on the power output, but the influence of windspeed and winddirection are minimal. TailAs a reminder, this is only a small attempt on PVOD and as such is deficient in many aspects. Also, the code can be found in my repository SmallSquare/PVOD_Regression. Thanks for reading.😉 ReferencesPVOD on Science Data Bank: PVOD v1.0: A photovoltaic power output dataset - Science Data Bank PVOD on Github: PVODataset PVOD on ScienceDirect: A photovoltaic power output dataset: Multi-source photovoltaic power output dataset with Python toolkit Machine Learning Modeling of Horizontal Photovoltaics Using Weather and Location Data Predicting solar power output using machine learning techniques Cyclical features encoding, it’s about time!","link":"/PVOD-regression/"},{"title":"LaTeX .gitignore file","text":"When using Git to synchronise LaTeX projects, some files should not be committed. These files could be LaTeX temporary files, your final generated pdf document or hidden files made by OS. Followings may need to be added to your .gitignore. 1234567891011121314.DS_Store.texpadtmpmain.pdfdraft*.pdf*.synctex(busy)*.aux*.bbl*.blg*.log*.synctex.gz*.fls*.fdb_latexmk*.out","link":"/LaTeX-gitignore-file/"}],"tags":[{"name":"整理","slug":"整理","link":"/tags/%E6%95%B4%E7%90%86/"},{"name":"技术","slug":"技术","link":"/tags/%E6%8A%80%E6%9C%AF/"},{"name":"EN","slug":"EN","link":"/tags/EN/"}],"categories":[{"name":"Hexo","slug":"Hexo","link":"/categories/Hexo/"},{"name":"娱乐","slug":"娱乐","link":"/categories/%E5%A8%B1%E4%B9%90/"},{"name":"CSGO","slug":"娱乐/CSGO","link":"/categories/%E5%A8%B1%E4%B9%90/CSGO/"},{"name":"LaTeX","slug":"LaTeX","link":"/categories/LaTeX/"},{"name":"CSDN","slug":"CSDN","link":"/categories/CSDN/"},{"name":"Windows","slug":"Windows","link":"/categories/Windows/"},{"name":"Powershell","slug":"Windows/Powershell","link":"/categories/Windows/Powershell/"},{"name":"Pycharm","slug":"Pycharm","link":"/categories/Pycharm/"},{"name":"Deep Learning","slug":"Deep-Learning","link":"/categories/Deep-Learning/"},{"name":"Machine Learning","slug":"Machine-Learning","link":"/categories/Machine-Learning/"}]}